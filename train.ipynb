{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGZB+uSjOQVQwx7HCYbfxa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/22Himanshu/AppliedMachineLearning/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Himanshu (MDS202328)"
      ],
      "metadata": {
        "id": "YB6Tm0AguVP1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Applied_ML_Spam_Classifier_1"
      ],
      "metadata": {
        "id": "lFIBPU6suVhI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Importing Libraries"
      ],
      "metadata": {
        "id": "cdc0FvGguwiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQNA6n7Wuffk",
        "outputId": "0dab79d8-dcf8-4e4f-c9e4-2c23de7c351b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_splits(data_dir):\n",
        "    \"\"\"Loads train, validation, and test datasets from CSV files.\"\"\"\n",
        "    train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n",
        "    val = pd.read_csv(os.path.join(data_dir, 'validation.csv'))\n",
        "    test = pd.read_csv(os.path.join(data_dir, 'test.csv'))\n",
        "    return train, val, test\n",
        "\n",
        "def vectorize_data(train, val, test):\n",
        "    \"\"\"Converts text data into TF-IDF vectors.\"\"\"\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    X_train = vectorizer.fit_transform(train['message'])\n",
        "    X_val = vectorizer.transform(val['message'])\n",
        "    X_test = vectorizer.transform(test['message'])\n",
        "    return X_train, X_val, X_test, train['label'], val['label'], test['label'], vectorizer\n",
        "\n",
        "def fit_model(X_train, y_train, model):\n",
        "    \"\"\"Fits a model on training data.\"\"\"\n",
        "    model.fit(X_train, y_train)\n",
        "    return model\n",
        "\n",
        "def score_model(model, X, y):\n",
        "    \"\"\"Scores a model on given data.\"\"\"\n",
        "    y_pred = model.predict(X)\n",
        "    return accuracy_score(y, y_pred), classification_report(y, y_pred)\n",
        "\n",
        "def evaluate_model(model, X_train, y_train, X_val, y_val):\n",
        "    \"\"\"Evaluates the model on both training and validation data.\"\"\"\n",
        "    train_acc, train_report = score_model(model, X_train, y_train)\n",
        "    val_acc, val_report = score_model(model, X_val, y_val)\n",
        "    print(f\"{model} Training Accuracy:\", train_acc)\n",
        "    print(f\"{model} Validation Accuracy:\", val_acc)\n",
        "    print(f\"{model} Validation Report:\\n\", val_report)\n",
        "    return train_acc, val_acc\n",
        "\n",
        "def fine_tune_model(X_train, y_train, X_val, y_val):\n",
        "    \"\"\"Fine-tunes hyperparameters using GridSearchCV.\"\"\"\n",
        "    param_grid = {'C': [0.1, 1, 10, 100]}\n",
        "    model = GridSearchCV(LogisticRegression(), param_grid, cv=3)\n",
        "    model.fit(X_train, y_train)\n",
        "    print(\"Best parameters:\", model.best_params_)\n",
        "    return model.best_estimator_\n",
        "\n",
        "def benchmark_models(X_train, y_train, X_val, y_val, X_test, y_test):\n",
        "    \"\"\"Trains and evaluates multiple models, selecting the best one.\"\"\"\n",
        "    models = {\n",
        "        'Naive Bayes': MultinomialNB(),\n",
        "        'Logistic Regression': LogisticRegression(),\n",
        "        'SVM': SVC()\n",
        "    }\n",
        "    best_model, best_acc = None, 0\n",
        "    for name, model in models.items():\n",
        "        model = fit_model(X_train, y_train, model)\n",
        "        _, val_acc = evaluate_model(model, X_train, y_train, X_val, y_val)\n",
        "        print(\"\\n-----------------------------------------------------------------\")\n",
        "        print(\"\\n\")\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            best_model = model\n",
        "    test_acc, test_report = score_model(best_model, X_test, y_test)\n",
        "    print(f\"The best model is {best_model}\")\n",
        "    print(\"Best Model Test Accuracy:\", test_acc)\n",
        "    print(\"Test Report:\\n\", test_report)\n",
        "    return best_model"
      ],
      "metadata": {
        "id": "haxCsmC2u6H5"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    data_dir = \"/content/drive/MyDrive/Applied_ML/data\"\n",
        "    train, val, test = load_splits(data_dir)\n",
        "    X_train, X_val, X_test, y_train, y_val, y_test, vectorizer = vectorize_data(train, val, test)\n",
        "    best_model = benchmark_models(X_train, y_train, X_val, y_val, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBHSkNm1u8Rt",
        "outputId": "b0227109-49f0-4483-cd27-0f373dfc0700"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultinomialNB() Training Accuracy: 0.9738461538461538\n",
            "MultinomialNB() Validation Accuracy: 0.9557416267942583\n",
            "MultinomialNB() Validation Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.98       724\n",
            "           1       1.00      0.67      0.80       112\n",
            "\n",
            "    accuracy                           0.96       836\n",
            "   macro avg       0.98      0.83      0.89       836\n",
            "weighted avg       0.96      0.96      0.95       836\n",
            "\n",
            "\n",
            "-----------------------------------------------------------------\n",
            "\n",
            "\n",
            "LogisticRegression() Training Accuracy: 0.9733333333333334\n",
            "LogisticRegression() Validation Accuracy: 0.9677033492822966\n",
            "LogisticRegression() Validation Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       724\n",
            "           1       1.00      0.76      0.86       112\n",
            "\n",
            "    accuracy                           0.97       836\n",
            "   macro avg       0.98      0.88      0.92       836\n",
            "weighted avg       0.97      0.97      0.97       836\n",
            "\n",
            "\n",
            "-----------------------------------------------------------------\n",
            "\n",
            "\n",
            "SVC() Training Accuracy: 0.997948717948718\n",
            "SVC() Validation Accuracy: 0.9808612440191388\n",
            "SVC() Validation Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       724\n",
            "           1       0.99      0.87      0.92       112\n",
            "\n",
            "    accuracy                           0.98       836\n",
            "   macro avg       0.98      0.93      0.96       836\n",
            "weighted avg       0.98      0.98      0.98       836\n",
            "\n",
            "\n",
            "-----------------------------------------------------------------\n",
            "\n",
            "\n",
            "The best model is SVC()\n",
            "Best Model Test Accuracy: 0.9832535885167464\n",
            "Test Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       724\n",
            "           1       0.99      0.88      0.93       112\n",
            "\n",
            "    accuracy                           0.98       836\n",
            "   macro avg       0.99      0.94      0.96       836\n",
            "weighted avg       0.98      0.98      0.98       836\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "foY2mEcsvCNL"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}